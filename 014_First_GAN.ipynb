{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "014_First_GAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYEVlW1ZbL33",
        "outputId": "29b9599b-9c2b-407e-9edc-bf1c1b6e9a27"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla K80 (UUID: GPU-b02f1f96-8a18-9b22-664f-858d43192d42)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9RVBrYgNmcD"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from tqdm.auto import tqdm\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.manual_seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wso_e4FxOLhR"
      },
      "source": [
        "def show_tensor_images(fake, real, num_images=25, size=(1, 28, 28)):\n",
        "\n",
        "    fake = (fake+1)/2\n",
        "    real = (real+1)/2\n",
        "\n",
        "    fake_unflat = fake.detach().cpu().view(-1, *size)\n",
        "    real_unflat = real.detach().cpu().view(-1, *size)\n",
        "\n",
        "    fake_grid = make_grid(fake_unflat[:num_images], nrow=5)\n",
        "    real_grid = make_grid(real_unflat[:num_images], nrow=5)\n",
        "\n",
        "    plt.figure(figsize=(10,3))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(fake_grid.permute(1, 2, 0).squeeze())\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(real_grid.permute(1, 2, 0).squeeze())\n",
        "    plt.show()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgAyw37PQR2i"
      },
      "source": [
        "## Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhNZDGN4OhKA"
      },
      "source": [
        "def get_generator_block(input_dim, output_dim):\n",
        "  return nn.Sequential(\n",
        "      nn.Linear(input_dim, output_dim),\n",
        "      nn.BatchNorm1d(output_dim),\n",
        "      nn.ReLU(inplace = True)\n",
        "  )"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyPQYYFyPWeX"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    # z_dim: the dimension of the noise vector, a scalar\n",
        "    # im_dim: the dimension of the images used, a scalar\n",
        "    # hidden_dim: the inner dimension, a scalar\n",
        "        \n",
        "    def __init__(self, z_dim = 10, im_dim = 784, hidden_dim = 128):\n",
        "        super(Generator, self).__init__()\n",
        "        self.gen = nn.Sequential(\n",
        "            get_generator_block(z_dim, hidden_dim),\n",
        "            get_generator_block(hidden_dim, hidden_dim * 2),\n",
        "            get_generator_block(hidden_dim * 2, hidden_dim * 4),\n",
        "            get_generator_block(hidden_dim * 4, hidden_dim * 8),\n",
        "            nn.Linear(hidden_dim * 8, im_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, noise):\n",
        "        # noise: a noise tensor with dimensions (n_samples, z_dim)\n",
        "        return self.gen(noise)\n",
        "    \n",
        "    def get_gen(self):\n",
        "        return self.gen"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecA4HdtNP9Xs"
      },
      "source": [
        "def get_noise(n_samples, z_dim, device='cuda'):\n",
        "  \n",
        "    return torch.randn(n_samples, z_dim, device=device)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvTEkcQVQbvH"
      },
      "source": [
        "## Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vadpcgqvQNo9"
      },
      "source": [
        "def get_discriminator_block(input_dim, output_dim):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(input_dim, output_dim),\n",
        "        nn.LeakyReLU(0.2, inplace=True))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmJCwmvFQmnN"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    # im_dim: the dimension of the images, fitted for the dataset used, a scalar\n",
        "    # hidden_dim: the inner dimension, a scalar\n",
        "\n",
        "    def __init__(self, im_dim=784, hidden_dim=128):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.disc = nn.Sequential(\n",
        "            get_discriminator_block(im_dim, hidden_dim * 4),\n",
        "            get_discriminator_block(hidden_dim * 4, hidden_dim * 2),\n",
        "            get_discriminator_block(hidden_dim * 2, hidden_dim),\n",
        "            nn.Linear(hidden_dim, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, image):\n",
        "        # Function for completing a forward pass of the discriminator: Given an image tensor,returns a 1-dimension tensor representing fake/real.\n",
        "        return self.disc(image)\n",
        "    \n",
        "    def get_disc(self):\n",
        "\n",
        "        return self.disc"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiAEfR6DRA-B"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "n_epochs = 100\n",
        "z_dim = 64\n",
        "display_step = 500\n",
        "batch_size = 128\n",
        "lr = 0.00001\n",
        "device = 'cuda'\n",
        "\n",
        "dataloader =DataLoader(MNIST('/files/', train=True, download=True,\n",
        "                       transform = transforms.ToTensor()),\n",
        "                       batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y30aRS6kRA8K"
      },
      "source": [
        "gen = Generator(z_dim).to(device)\n",
        "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr)\n",
        "disc = Discriminator().to(device) \n",
        "disc_opt = torch.optim.Adam(disc.parameters(), lr=lr)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUq4mzmGRLql"
      },
      "source": [
        "def get_disc_loss(gen, disc, criterion, real, num_images, z_dim, device):\n",
        "\n",
        "    fake_noise = get_noise(num_images, z_dim, device=device)\n",
        "    fake = gen(fake_noise)\n",
        "    disc_fake_pred = disc(fake.detach())\n",
        "    disc_fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n",
        "    disc_real_pred = disc(real)\n",
        "    disc_real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred))\n",
        "    disc_loss = (disc_fake_loss + disc_real_loss) / 2\n",
        "    return disc_loss"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmWlyGJuRwdJ"
      },
      "source": [
        "def get_gen_loss(gen, disc, criterion, num_images, z_dim, device):\n",
        "\n",
        "    fake_noise = get_noise(num_images, z_dim, device=device)\n",
        "    fake = gen(fake_noise)\n",
        "    disc_fake_pred = disc(fake)\n",
        "    gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n",
        "\n",
        "    return gen_loss"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSEvuhRuR1gE"
      },
      "source": [
        "cur_step = 0\n",
        "mean_generator_loss = 0\n",
        "mean_discriminator_loss = 0\n",
        "test_generator = True\n",
        "gen_loss = False\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    for real, _ in tqdm(dataloader):\n",
        "        cur_batch_size = len(real)\n",
        "\n",
        "        # Flatten the batch of real images from the dataset\n",
        "        real = real.view(cur_batch_size, -1).to(device)\n",
        "\n",
        "        # Zero out the gradients before backpropagation\n",
        "        disc_opt.zero_grad()\n",
        "\n",
        "        # Calculate discriminator loss\n",
        "        disc_loss = get_disc_loss(gen, disc, criterion, real, cur_batch_size, z_dim, device)\n",
        "\n",
        "        # Update gradients\n",
        "        disc_loss.backward(retain_graph=True)\n",
        "\n",
        "        # Update optimizer\n",
        "        disc_opt.step()\n",
        "\n",
        "        # Zero out the gradients before backpropagation\n",
        "        gen_opt.zero_grad()\n",
        "\n",
        "        # Calculate generator loss\n",
        "        gen_loss = get_gen_loss(gen, disc, criterion, cur_batch_size, z_dim, device)\n",
        "\n",
        "        # Update Gradients\n",
        "        gen_loss.backward()\n",
        "\n",
        "        # Update optimizer\n",
        "        gen_opt.step()\n",
        "\n",
        "        # Average discriminator loss\n",
        "        mean_discriminator_loss += disc_loss.item() / display_step\n",
        "\n",
        "        # Average generator loss\n",
        "        mean_generator_loss += gen_loss.item() / display_step\n",
        "\n",
        "        if cur_step % display_step == 0 and cur_step > 0:\n",
        "            print(f\"Step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n",
        "            fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n",
        "            fake = gen(fake_noise)\n",
        "            show_tensor_images(fake, real)\n",
        "            mean_generator_loss = 0\n",
        "            mean_discriminator_loss = 0\n",
        "        cur_step += 1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}