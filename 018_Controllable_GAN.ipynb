{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "018_Controllable_GAN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "txw4b_cHiegw"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xa8GVWoaiOkH"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from tqdm.auto import tqdm\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.datasets import CelebA\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "torch.manual_seed(0)\n",
        "\n",
        "def show_tensor_images(image_tensor, num_images=16, size=(3, 64, 64), nrow=3):\n",
        "    image_tensor = (image_tensor + 1) / 2\n",
        "    image_unflat = image_tensor.detach().cpu()\n",
        "    image_grid = make_grid(image_unflat[:num_images], nrow=nrow)\n",
        "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8it73s-Eic79"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim=10, im_chan=3, hidden_dim=64):\n",
        "        super(Generator, self).__init__()\n",
        "        self.z_dim = z_dim\n",
        "        # Build the neural network\n",
        "        self.gen = nn.Sequential(\n",
        "            self.make_gen_block(z_dim, hidden_dim * 8),\n",
        "            self.make_gen_block(hidden_dim * 8, hidden_dim * 4),\n",
        "            self.make_gen_block(hidden_dim * 4, hidden_dim * 2),\n",
        "            self.make_gen_block(hidden_dim * 2, hidden_dim),\n",
        "            self.make_gen_block(hidden_dim, im_chan, kernel_size=4, final_layer=True),\n",
        "        )\n",
        "\n",
        "    def make_gen_block(self, input_channels, output_channels, kernel_size=3, stride=2, final_layer=False):\n",
        "        if not final_layer:\n",
        "            return nn.Sequential(\n",
        "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
        "                nn.BatchNorm2d(output_channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "            )\n",
        "        else:\n",
        "            return nn.Sequential(\n",
        "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
        "                nn.Tanh(),\n",
        "            )\n",
        "\n",
        "    def forward(self, noise):\n",
        "        x = noise.view(len(noise), self.z_dim, 1, 1)\n",
        "        return self.gen(x)\n",
        "\n",
        "def get_noise(n_samples, z_dim, device='cpu'):\n",
        "    return torch.randn(n_samples, z_dim, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "up4Jzg6bimJB"
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, im_chan=3, n_classes=2, hidden_dim=64):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.classifier = nn.Sequential(\n",
        "            self.make_classifier_block(im_chan, hidden_dim),\n",
        "            self.make_classifier_block(hidden_dim, hidden_dim * 2),\n",
        "            self.make_classifier_block(hidden_dim * 2, hidden_dim * 4, stride=3),\n",
        "            self.make_classifier_block(hidden_dim * 4, n_classes, final_layer=True),\n",
        "        )\n",
        "\n",
        "    def make_classifier_block(self, input_channels, output_channels, kernel_size=4, stride=2, final_layer=False):\n",
        "        if final_layer:\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(input_channels, output_channels, kernel_size, stride),\n",
        "            )\n",
        "        else:\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(input_channels, output_channels, kernel_size, stride),\n",
        "                nn.BatchNorm2d(output_channels),\n",
        "                nn.LeakyReLU(0.2, inplace=True),\n",
        "            )\n",
        "\n",
        "    def forward(self, image):\n",
        "        class_pred = self.classifier(image)\n",
        "        return class_pred.view(len(class_pred), -1)"
      ],
      "execution_count":null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMFV29aiityc"
      },
      "source": [
        "z_dim = 64\n",
        "batch_size = 128\n",
        "device = 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17pA_e2PiwR1"
      },
      "source": [
        "def train_classifier(filename):\n",
        "    import seaborn as sns\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    label_indices = range(40)\n",
        "\n",
        "    n_epochs = 3\n",
        "    display_step = 500\n",
        "    lr = 0.001\n",
        "    beta_1 = 0.5\n",
        "    beta_2 = 0.999\n",
        "    image_size = 64\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(image_size),\n",
        "        transforms.CenterCrop(image_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ])\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        CelebA(\".\", split='train', download=True, transform=transform),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True)\n",
        "\n",
        "    classifier = Classifier(n_classes=len(label_indices)).to(device)\n",
        "    class_opt = torch.optim.Adam(classifier.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    cur_step = 0\n",
        "    classifier_losses = []\n",
        "    for epoch in range(n_epochs):\n",
        "        for real, labels in tqdm(dataloader):\n",
        "            real = real.to(device)\n",
        "            labels = labels[:, label_indices].to(device).float()\n",
        "\n",
        "            class_opt.zero_grad()\n",
        "            class_pred = classifier(real)\n",
        "            class_loss = criterion(class_pred, labels)\n",
        "            class_loss.backward()\n",
        "            class_opt.step()\n",
        "            classifier_losses += [class_loss.item()]\n",
        "\n",
        "            ## Visualization code ##\n",
        "            if cur_step % display_step == 0 and cur_step > 0:\n",
        "                class_mean = sum(classifier_losses[-display_step:]) / display_step\n",
        "                print(f\"Step {cur_step}: Classifier loss: {class_mean}\")\n",
        "                step_bins = 20\n",
        "                x_axis = sorted([i * step_bins for i in range(len(classifier_losses) // step_bins)] * step_bins)\n",
        "                sns.lineplot(x_axis, classifier_losses[:len(x_axis)], label=\"Classifier Loss\")\n",
        "                plt.legend()\n",
        "                plt.show()\n",
        "                torch.save({\"classifier\": classifier.state_dict()}, filename)\n",
        "            cur_step += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2eJ8yx1jx4Z"
      },
      "source": [
        "!wget -q -O pretrained_celeba.pth \"https://drive.google.com/uc?id=1Hp3A7cAmCPWwPtKzp9sj91jF1szwioJS\"\n",
        "!wget -q -O pretrained_classifier.pth \"https://drive.google.com/uc?id=1-8OsxfPiUHVB8vNtJCLrPDMMkuKKNDU7\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcdIqcgOi6j6"
      },
      "source": [
        "import torch\n",
        "import pickle\n",
        "gen = Generator(z_dim).to(device)\n",
        "gen_dict = torch.load(\"pretrained_celeba.pth\", map_location=torch.device(device))[\"gen\"]\n",
        "gen.load_state_dict(gen_dict)\n",
        "gen.eval()\n",
        "\n",
        "n_classes = 40\n",
        "classifier = Classifier(n_classes=n_classes).to(device)\n",
        "class_dict = torch.load(\"pretrained_classifier.pth\", map_location=torch.device(device))[\"classifier\"]\n",
        "classifier.load_state_dict(class_dict)\n",
        "classifier.eval()\n",
        "print(\"Loaded the models!\")\n",
        "\n",
        "opt = torch.optim.Adam(classifier.parameters(), lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxbiYysvi904"
      },
      "source": [
        "def calculate_updated_noise(noise, weight):\n",
        "    new_noise = noise + noise.grad * weight\n",
        "    return new_noise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arTYSMPwjBd9"
      },
      "source": [
        "n_images = 8\n",
        "fake_image_history = []\n",
        "grad_steps = 1 # Number of gradient steps to take\n",
        "skip = 2\n",
        "\n",
        "feature_names = [\"5oClockShadow\", \"ArchedEyebrows\", \"Attractive\", \"BagsUnderEyes\", \"Bald\", \"Bangs\",\n",
        "\"BigLips\", \"BigNose\", \"BlackHair\", \"BlondHair\", \"Blurry\", \"BrownHair\", \"BushyEyebrows\", \"Chubby\",\n",
        "\"DoubleChin\", \"Eyeglasses\", \"Goatee\", \"GrayHair\", \"HeavyMakeup\", \"HighCheekbones\", \"Male\", \n",
        "\"MouthSlightlyOpen\", \"Mustache\", \"NarrowEyes\", \"NoBeard\", \"OvalFace\", \"PaleSkin\", \"PointyNose\", \n",
        "\"RecedingHairline\", \"RosyCheeks\", \"Sideburn\", \"Smiling\", \"StraightHair\", \"WavyHair\", \"WearingEarrings\", \n",
        "\"WearingHat\", \"WearingLipstick\", \"WearingNecklace\", \"WearingNecktie\", \"Young\"]\n",
        "\n",
        "target_indices = feature_names.index(\"Smiling\")\n",
        "\n",
        "noise = get_noise(n_images, z_dim).to(device).requires_grad_()\n",
        "for i in range(grad_steps):\n",
        "    opt.zero_grad()\n",
        "    fake = gen(noise)\n",
        "    fake_image_history += [fake]\n",
        "    fake_classes_score = classifier(fake)[:, target_indices].mean()\n",
        "    fake_classes_score.backward()\n",
        "    noise.data = calculate_updated_noise(noise, 1 / grad_steps)\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [n_images * 2, grad_steps * 2]\n",
        "show_tensor_images(torch.cat(fake_image_history[::skip], dim=2), num_images=n_images, nrow=n_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF2G6k2BjKIN"
      },
      "source": [
        "def get_score(current_classifications, original_classifications, target_indices, other_indices, penalty_weight):\n",
        "  \n",
        "    other_distances = current_classifications[:, other_indices] - original_classifications[:, other_indices]\n",
        "    other_class_penalty = -torch.norm(other_distances, dim=1).mean() * penalty_weight\n",
        "    target_score = current_classifications[:, target_indices].mean()\n",
        "    return target_score + other_class_penalty"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-MkmDyhjQ7h"
      },
      "source": [
        "fake_image_history = []\n",
        "target_indices = feature_names.index(\"Smiling\")\n",
        "other_indices = [cur_idx != target_indices for cur_idx, _ in enumerate(feature_names)]\n",
        "noise = get_noise(n_images, z_dim).to(device).requires_grad_()\n",
        "original_classifications = classifier(gen(noise)).detach()\n",
        "for i in range(grad_steps):\n",
        "    opt.zero_grad()\n",
        "    fake = gen(noise)\n",
        "    fake_image_history += [fake]\n",
        "    fake_score = get_score(\n",
        "        classifier(fake), \n",
        "        original_classifications,\n",
        "        target_indices,\n",
        "        other_indices,\n",
        "        penalty_weight=0.1\n",
        "    )\n",
        "    fake_score.backward()\n",
        "    noise.data = calculate_updated_noise(noise, 1 / grad_steps)\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [n_images * 2, grad_steps * 2]\n",
        "show_tensor_images(torch.cat(fake_image_history[::skip], dim=2), num_images=n_images, nrow=n_images)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
